{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "import models\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from cv_bridge import CvBridge, CvBridgeError\n",
    "from PIL import Image\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "CHANNEL = 3\n",
    "DEPTH_IMAGE_WIDTH = 160\n",
    "DEPTH_IMAGE_HEIGHT = 128\n",
    "RGB_IMAGE_WIDTH = 304\n",
    "RGB_IMAGE_HEIGHT = 228\n",
    "MAX_STEP = 200\n",
    "MAX_EPOCH = 150\n",
    "BATCH = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_predict(predict, kinect, rgb, epoch, step):\n",
    "\tmax_val = 10.\n",
    "\tkinect[kinect>max_val] = max_val\n",
    "\tif np.max(kinect) != 0:\n",
    "\t\tkinect_save = (kinect/max_val)*255.0\n",
    "\t\t# print('kinect_max', np.amax(kinect))\n",
    "\telse:\n",
    "\t\tkinect_save = kinect*255.0\n",
    "\tkinect_save=np.uint8(kinect_save)\n",
    "\tname = \"data/%04d\" % epoch + \"_%04d_kinect.png\" % step\n",
    "\tcv2.imwrite(name,kinect_save)\n",
    "\n",
    "\tpredict[predict>max_val] = max_val\n",
    "\tif np.max(predict) != 0:\n",
    "\t\tpredict_save = (predict/max_val)*255.0\n",
    "\t\t# print('predict_max', np.amax(predict))\n",
    "\telse:\n",
    "\t\tpredict_save = predict*255.0\n",
    "\tpredict_save=np.uint8(predict_save)\n",
    "\tname = \"data/%04d\" % epoch + \"_%04d_predicted.png\" % step\n",
    "\tcv2.imwrite(name,predict_save)\n",
    "\n",
    "\tname = \"data/%04d\" % epoch + \"_%04d_rgb.png\" % step\n",
    "\tcv2.imwrite(name,rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetDiff(first, second):\n",
    "\tsecond = set(second)\n",
    "\treturn [item for item in first if item not in second]\n",
    "\n",
    "def normalize_rgb(rgb_images, value):\n",
    "\trgb_images = np.asarray(rgb_images).astype(float)\n",
    "\trgb_images /= 255.\n",
    "\tfor x in range(3):\n",
    "\t\trgb_images[:, :, :, x] -= value[x]\n",
    "\treturn rgb_images\n",
    "\n",
    "def consecutive_sample(data, start, end):\n",
    "\t# return a list\n",
    "\tpart = []\n",
    "\tfor x in range(start, end):\n",
    "\t\tpart.append(data[x])\n",
    "\treturn part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable conv1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Piyushkumar\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\Piyushkumar\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Piyushkumar\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1f70d551b480>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[1;31m# Construct network and define loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRGB_IMAGE_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRGB_IMAGE_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHANNEL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNet50UpProj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mdepth_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mdepth_kinect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEPTH_IMAGE_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEPTH_IMAGE_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Monocular-Obstacle-Avoidance-master\\Depth\\FCRN\\models\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, batch, keep_prob, is_training, trainable)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Monocular-Obstacle-Avoidance-master\\Depth\\FCRN\\models\\fcrn.py\u001b[0m in \u001b[0;36msetup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtrainable_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         (self.feed('data')\n\u001b[1;32m----> 8\u001b[1;33m              \u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable_flag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m              \u001b[1;33m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bn_conv1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable_flag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m              \u001b[1;33m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pool1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Monocular-Obstacle-Avoidance-master\\Depth\\FCRN\\models\\network.py\u001b[0m in \u001b[0;36mlayer_decorated\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mlayer_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# Perform the operation and get the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;31m# Add to layer LUT.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Monocular-Obstacle-Avoidance-master\\Depth\\FCRN\\models\\network.py\u001b[0m in \u001b[0;36mconv\u001b[1;34m(self, input_data, k_h, k_w, c_o, s_h, s_w, name, relu, padding, group, biased, trainable)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weights'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_i\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_o\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Monocular-Obstacle-Avoidance-master\\Depth\\FCRN\\models\\network.py\u001b[0m in \u001b[0;36mmake_var\u001b[1;34m(self, name, shape, trainable)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;34m'''Creates a new TensorFlow variable.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'float32'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidate_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1465\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1467\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1215\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    525\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    479\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    846\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 848\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable conv1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Piyushkumar\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\Piyushkumar\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Piyushkumar\\Anaconda3\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\t# Construct network and define loss function\n",
    "\tstate = tf.placeholder(\"float\", [None, RGB_IMAGE_HEIGHT, RGB_IMAGE_WIDTH, CHANNEL])\n",
    "\tnet = models.ResNet50UpProj({'data': state}, BATCH, 1, True)\n",
    "\tdepth_predict = net.get_output()\n",
    "\tdepth_kinect = tf.placeholder(\"float\", [None, DEPTH_IMAGE_HEIGHT, DEPTH_IMAGE_WIDTH, 1])\n",
    "\timg_mask = tf.placeholder(\"float\", [None, DEPTH_IMAGE_HEIGHT, DEPTH_IMAGE_WIDTH, 1])\n",
    "\n",
    "\tprint('Loading initial network param')\n",
    "\tinit_saver = tf.train.Saver()     \n",
    "\tinit_saver.restore(sess, '../init_network/NYU_FCRN.ckpt')\n",
    "\n",
    "\td_show = tf.subtract(tf.multiply(depth_predict, img_mask), tf.multiply(depth_kinect, img_mask))\n",
    "\tabs_d_show = tf.abs(d_show)\n",
    "\tc = tf.divide(tf.reduce_max(abs_d_show), 5.)\n",
    "\tberHu = tf.where(tf.less_equal(abs_d_show, c), abs_d_show, tf.square(d_show))\n",
    "\tloss = tf.reduce_mean(tf.reduce_mean(berHu, 1))\n",
    "\n",
    "\ttrain_step = tf.train.AdamOptimizer(5e-5).minimize(loss)\n",
    "\n",
    "\ttrain_loss_var = tf.Variable(0., trainable=False)\n",
    "\ttrain_loss_sum = tf.summary.scalar('training_loss', train_loss_var)\n",
    "\ttest_loss_var = tf.Variable(0., trainable=False)\n",
    "\ttest_loss_sum = tf.summary.scalar('testing_loss', test_loss_var)\n",
    "\tmerged_summary = tf.summary.merge_all()\n",
    "\tsummary_writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "\n",
    "\tprint('Initializing var')\n",
    "\tuninitialized_vars = []\n",
    "\tstart_time = time.time()\n",
    "\tfor var in tf.global_variables():\n",
    "\t\ttry:\n",
    "\t\t\tsess.run(var)\n",
    "\t\texcept tf.errors.FailedPreconditionError:               \n",
    "\t\t\tuninitialized_vars.append(var)\n",
    "\tinit_new_vars_op = tf.variables_initializer(uninitialized_vars)\n",
    "\tprint(\"  [*] printing unitialized variables\")\n",
    "\tfor idx, v in enumerate(uninitialized_vars):\n",
    "\t\tprint((\"  var {:3}: {:15}   {}\".format(idx, str(v.get_shape()), v.name)))\n",
    "\tsess.run(init_new_vars_op)\n",
    "\tprint('Var initialized, time:', time.time() - start_time)\n",
    "\n",
    "\ttrainable_var = tf.trainable_variables()\n",
    "\tprint(\"  [*] printing trainable variables\")\n",
    "\tfor idx, v in enumerate(trainable_var):\n",
    "\t\tprint((\"  var {:3}: {:15}   {}\".format(idx, str(v.get_shape()), v.name)))\n",
    "\n",
    "\tdepth_net_saver = tf.train.Saver(trainable_var, max_to_keep=1)\n",
    "\tcheckpoint = tf.train.get_checkpoint_state('saved_network')\n",
    "\tif checkpoint and checkpoint.model_checkpoint_path:\n",
    "\t\tprint('Loading from checkpoint:', checkpoint)\n",
    "\t\tdepth_net_saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "\t\tprint(\"Depth network model loaded:\", checkpoint.model_checkpoint_path)\n",
    "\telse:\n",
    "\t\tprint('No new model')\n",
    "\n",
    "\tprint('Loading data')\n",
    "\ttraining_data = pickle.load(open('../rgb_depth_images_training_real.p', \"rb\"))\n",
    "\ttesting_data = pickle.load(open('../rgb_depth_images_testing_real.p', \"rb\"))\n",
    "\tprint('Data loaded')\n",
    "\n",
    "\tStep = 0\n",
    "\tfor epoch in range(1,MAX_EPOCH+1):\n",
    "\t\tnp.random.shuffle(training_data)\n",
    "\t\tnp.random.shuffle(testing_data)\n",
    "\t\tfor step in range(1,int(len(training_data)/(BATCH))+1):\n",
    "\t\t\tstart_time = time.time()\n",
    "\t\t\ttraining_batch_real = consecutive_sample(training_data, (step-1)*BATCH, step*BATCH)\n",
    "\n",
    "\t\t\trgb_img = [d[0] for d in training_batch_real]\n",
    "\t\t\tdepth_img = [d[1] for d in training_batch_real]\n",
    "\t\t\tdepth_img = np.reshape(depth_img, [-1, DEPTH_IMAGE_HEIGHT, DEPTH_IMAGE_WIDTH, 1])\n",
    "\t\t\tmask = [d[2] for d in training_batch_real]\n",
    "\t\t\tmask = np.reshape(mask, [-1, DEPTH_IMAGE_HEIGHT, DEPTH_IMAGE_WIDTH, 1])\n",
    "\n",
    "\t\t\t# flip\n",
    "\t\t\tif np.random.rand() > 0.5:\n",
    "\t\t\t\trgb_img = np.flip(rgb_img, axis=2)\n",
    "\t\t\t\tdepth_img = np.flip(depth_img, axis=2)\n",
    "\t\t\t\tmask = np.flip(mask, axis=2)\n",
    "\n",
    "\t\t\ttraining_loss = 0.\n",
    "\t\t\tdepth_predict_value, _, training_loss = sess.run([depth_predict, train_step, loss], \n",
    "\t\t\t\t \t\t\t\t\t\tfeed_dict = { state : rgb_img,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  depth_kinect : depth_img,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  img_mask : mask})\n",
    "\n",
    "\t\t\tif step % 10 == 0:\n",
    "\t\t\t\ttesting_batch = random.sample(testing_data, BATCH)\n",
    "\t\t\t\trgb_img_test = [d[0] for d in testing_batch]\n",
    "\t\t\t\tdepth_img_test = [d[1] for d in testing_batch]\n",
    "\t\t\t\tdepth_img_test = np.reshape(depth_img_test, [-1, DEPTH_IMAGE_HEIGHT, DEPTH_IMAGE_WIDTH, 1])\n",
    "\t\t\t\tmask_test = [d[2] for d in testing_batch]\n",
    "\t\t\t\tmask_test = np.reshape(mask_test, [-1, DEPTH_IMAGE_HEIGHT, DEPTH_IMAGE_WIDTH, 1])\n",
    "\t\t\t\tdepth_predict_value, testing_loss, difference= sess.run([depth_predict, loss, abs_d_show], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  feed_dict = { state : rgb_img_test,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdepth_kinect : depth_img_test,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\timg_mask : mask_test})\n",
    "\t\t\t\t# if epoch % 10 == 0:\n",
    "\t\t\t\toutput_predict(depth_predict_value[0], depth_img_test[0], np.asarray(rgb_img_test)[0], epoch, step)\n",
    "\t\t\t\t# print(\"epoch: {:2} | step: {:3} | traning loss: {:.4f} | testing loss: {:.4f}, time: {:.2f}\"\\\n",
    "\t\t\t\t# \t\t.format(epoch, step, training_loss, testing_loss, (time.time()-start_time)/60.))\n",
    "\t\t\t\tsummary_str = sess.run(merged_summary, feed_dict={train_loss_var: training_loss, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  test_loss_var: testing_loss})\n",
    "\t\t\t\tsummary_writer.add_summary(summary_str, Step)\n",
    "\t\t\t\tStep = Step + 1\n",
    "\n",
    "\t\t# full testing\n",
    "\t\ttesting_loss_buff = []\n",
    "\t\tfor step in range(int(len(testing_data)/(BATCH))):\n",
    "\t\t\ttesting_batch = consecutive_sample(testing_data, (step-1)*BATCH, step*BATCH)\n",
    "\t\t\trgb_img_test = [d[0] for d in testing_batch]\n",
    "\t\t\tdepth_img_test = [d[1] for d in testing_batch]\n",
    "\t\t\tmask_test = [d[2] for d in testing_batch]\n",
    "\t\t\tmask_test = np.reshape(mask_test, [-1, DEPTH_IMAGE_HEIGHT, DEPTH_IMAGE_WIDTH, 1])\n",
    "\n",
    "\t\t\tdepth_predict_value, testing_loss, difference = sess.run([depth_predict, loss, abs_d_show], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  feed_dict = { state : rgb_img_test,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdepth_kinect : depth_img_test,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\timg_mask : mask_test})\n",
    "\t\t\ttesting_loss_buff.append(testing_loss)\n",
    "\n",
    "\t\tprint((\"epoch: {:3} | traning loss: {:.4f} | testing loss: {:.4f}, time: {:.2f}\"\\\n",
    "\t\t\t\t.format(epoch, training_loss, np.mean(testing_loss_buff), (time.time()-start_time)/60.)))\n",
    "\t\tif epoch % 30 == 0:\n",
    "\t\t\tdepth_net_saver.save(sess, 'saved_network/DepthNet', global_step = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
